{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries.\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('regression').getOrCreate()\n",
    "\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 8, 5\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataFrame_Initial from VideoGamesSales.csv file.\n",
    "dataFrame_Initial = spark.read.csv('../Datasets/VideoGamesSales.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data point count for dataFrame_Initial.\n",
    "print(\"Total data points:\", dataFrame_Initial.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema table for dataFrame_Initial.\n",
    "dataFrame_Initial.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General statistics for 'Year_of_Release'\n",
    "dataFrame_Initial.select('Year_of_Release').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame_Initial.filter(\"Year_of_Release > 2000 AND Year_of_Release < 2017\").select('Year_of_Release').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dataFrame_Initial to remove empty values.\n",
    "dataFrame_Filtered = dataFrame_Initial.na.drop()\n",
    "\n",
    "# Filter dataFrame_Filtered by 'Year_of_Release'\n",
    "dataFrame_Filtered = dataFrame_Filtered.orderBy('Year_of_Release')\n",
    "\n",
    "# Check dataFrame has been filtered. \n",
    "dataFrame_Filtered.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data point count for dataFrame_Filtered.\n",
    "print(\"Total data points:\", dataFrame_Filtered.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add key column, 'ID' to dataFrame.\n",
    "dataFrame_wKey = dataFrame_Filtered.select('*').withColumn('ID', monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set column types to accurately reflect data.\n",
    "dataFrame_wKey = dataFrame_wKey.withColumn('User_Score', dataFrame_wKey['User_Score'].cast('float'))\n",
    "dataFrame_wKey = dataFrame_wKey.withColumn('Year_of_Release', dataFrame_wKey['Year_of_Release'].cast('int'))\n",
    "dataFrame_wKey = dataFrame_wKey.withColumn('User_Count', dataFrame_wKey['User_Count'].cast('int'))\n",
    "dataFrame_wKey = dataFrame_wKey.withColumn('Critic_Count', dataFrame_wKey['Critic_Count'].cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema table with columns set to correct data type.\n",
    "dataFrame_wKey.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of columns deemed useful.\n",
    "columns_Useful = ['ID', 'Name', 'Platform', 'Year_of_Release', 'Genre', \n",
    "               'Global_Sales', 'Critic_Score', 'Critic_Count',\n",
    "               'User_Score', 'User_Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe which contains only useful columns.\n",
    "dataFrame_Useful = dataFrame_wKey[columns_Useful]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first 5 rows of dataFrame_Useful\n",
    "dataFrame_Useful.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df_Useful = dataFrame_Useful.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of columns for input.\n",
    "input_Columns = ['ID', 'Year_of_Release', 'Critic_Score', 'User_Score']\n",
    "\n",
    "vector_Assembler = VectorAssembler(inputCols = input_Columns, outputCol = 'Features')\n",
    "\n",
    "# Transform the data.\n",
    "vector_Output = vector_Assembler.transform(dataFrame_Useful)\n",
    "\n",
    "# Schema table with Features column added.\n",
    "vector_Output.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe with only Features and GlobalSales columns\n",
    "vector_output = vector_Output.select(['Features','Global_Sales'])\n",
    "\n",
    "# dataFrame_Features now has only 2 columns\n",
    "print(vector_output.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data by amounts stated above\n",
    "data_train,data_test = vector_output.randomSplit([0.7,0.3])\n",
    "\n",
    "# Show data_train\n",
    "data_train.show()\n",
    "\n",
    "# Show data_test\n",
    "data_test.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "regression = LinearRegression(featuresCol='Features', labelCol='Global_Sales')\n",
    "\n",
    "# Fit the training data.\n",
    "regression_Model = regression.fit(data_train)\n",
    "\n",
    "# Print the coefficients and intercept.\n",
    "#print(\"Liner Regression Coefficients: \" + str(regression_Model.coefficients))\n",
    "#print(\"Linear Regression Intercept: \" + str(regression_Model.intercept))\n",
    "\n",
    "# Summarise the model\n",
    "#summary = regression_Model.summary\n",
    "\n",
    "# Print RMSE and R2\n",
    "#print(\"Linear Regression RMSE on training data: \" + str(summary.rootMeanSquaredError))\n",
    "#print(\"Linear Regression R2 on training data: \" + str(summary.r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'regression_Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-073d89e9d015>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Visualize the coefficients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregression_Model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefficient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Initial plot of data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'regression_Model' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualize the coefficients.\n",
    "beta = np.sort(regression_Model.coefficient)\n",
    "\n",
    "# Initial plot of data.\n",
    "plt.plot(beta)\n",
    "\n",
    "# Add a label to y-axis of plot.\n",
    "plt.ylabel('Beta Coefficients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_Test = regression_Model.evaluate(data_Test)\n",
    "\n",
    "# Print RMSE and R2\n",
    "print(\"Linear Regression RMSE on test data: \" + str(results_test.rootMeanSquaredError))\n",
    "print(\"Linear Regression R2 on test data: \" + str(results_Test.r2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
